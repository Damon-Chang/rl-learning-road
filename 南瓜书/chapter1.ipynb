{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 强化学习实验\n",
    "OpenAI开源的Gym库是一个仿真库，包含很多现有的环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agent():\n",
    "    agent = Agent()\n",
    "    agent.load_state_dict(torch.load('agent.pth'))\n",
    "    agent.eval()\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\")\n",
    "observation = env.reset()\n",
    "agent = load_agent() # 函数未定义\n",
    "for step in range(100):\n",
    "    action = agent(observation)\n",
    "    observation, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/envs/registration.py:592: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "2025-02-28 20:58:34.350 python[29341:1566945] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-28 20:58:34.350 python[29341:1566945] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0324772  -0.17753255 -0.00565475  0.2753821 ]\n",
      "[-0.03602784  0.01766961 -0.00014711 -0.01907897]\n",
      "[-0.03567445  0.21279368 -0.00052869 -0.31180832]\n",
      "[-0.03141858  0.40792316 -0.00676486 -0.60465795]\n",
      "[-0.02326012  0.21289645 -0.01885802 -0.3141134 ]\n",
      "[-0.01900219  0.01804814 -0.02514028 -0.02743685]\n",
      "[-0.01864123 -0.17670442 -0.02568902  0.2572092 ]\n",
      "[-0.02217531 -0.37145036 -0.02054484  0.54168004]\n",
      "[-0.02960432 -0.17604578 -0.00971124  0.24259523]\n",
      "[-0.03312524 -0.37102768 -0.00485933  0.5321992 ]\n"
     ]
    }
   ],
   "source": [
    "# 每个训练中都要使用的返回值有observation，action，reward，done，info\n",
    "# observation的结构会犹豫游戏的不同而发生变化\n",
    "# 以CartPole-v0为例\n",
    "env = gym.make('CartPole-v0') # 创建游戏环境\n",
    "env.reset() # 重置一个回合\n",
    "for _ in range(10):\n",
    "    env.render() # 现实图形界面\n",
    "    action = env.action_space.sample() # 在该游戏的所有动作空间中随意选择一个作为输出\n",
    "    '''进一步可由智能体的算法得到'''\n",
    "    #env.step(action) # 用于提交动作，括号内是具体的动作 有四个返回值\n",
    "    observation, reward, done, info = env.step(action) # 用于\n",
    "    print(observation)\n",
    "\n",
    "env.close() # 关闭环境 注意：如果绘制了实验的图形界面窗口，那么关闭该窗口最佳方式是调用env.close() 试图关闭图形界面窗口可能会导致内存不能释放 甚至会导致死机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中`env.step()`完成了一个完整的$S\\rightarrow A\\rightarrow R\\rightarrow S'$的循环，其中$S'$就是下一个状态，$R$就是当前状态$S$下，执行动作$A$所获得的奖励。只要我们不断观测这样的过程，并让智能体在其中应用相应的算法完成训练，就能得到一个高质量的强化学习模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/envs/registration.py:421: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# 查看Gym以注册的环境\n",
    "# Gym库中的每个环境和动作空间和观测空间\n",
    "from gym import envs\n",
    "env_specs = envs.registry.all()\n",
    "env_ids = [env_spec.id for env_spec in env_specs]\n",
    "print(len(env_ids),env_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "观测空间 = Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "动作空间 = Discrete(3)\n",
      "观测空间范围 = ([-1.2  -0.07] ~ [0.6  0.07])\n",
      "动作数 = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "# 用小车上山MountainCar-v0作为例子\n",
    "# 学习如何与Gym库进行交互\n",
    "#import gym\n",
    "env = gym.make('MountainCar-v0')\n",
    "print(\"观测空间 = {}\".format(env.observation_space))\n",
    "print(\"动作空间 = {}\".format(env.action_space))\n",
    "print(\"观测空间范围 = ({} ~ {})\".format(env.observation_space.low, env.observation_space.high))\n",
    "print(\"动作数 = {}\".format(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现智能体控制小车移动\n",
    "class SimpleAgent():\n",
    "    def __init__(self, env):\n",
    "        pass\n",
    "\n",
    "    def decide(self, observation):\n",
    "        position, velocity = observation # 获取当前状态 [位置,速度]\n",
    "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
    "                 0.3 * (position + 0.9) ** 4 - 0.008)\n",
    "        rb = -0.07 * (position + 0.38) ** 2 + 0.07\n",
    "        if lb < velocity < rb:\n",
    "            action = 2\n",
    "        else:\n",
    "            action = 0\n",
    "        return action\n",
    "    \n",
    "    def learn(self, *args):\n",
    "        pass\n",
    "\n",
    "agent = SimpleAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 试图让智能体与环境进行交互\n",
    "def play(env, agent, render=False, train=False):\n",
    "    episode_reward = 0. # 记录回合总奖励，初始值为0\n",
    "    observation = env.reset() # 重制游戏环境，开始新回合\n",
    "    while True: # 不断循环，直到回合结束\n",
    "        if render: # 是否显示游戏画面\n",
    "            env.render() # 显示游戏画面\n",
    "        action = agent.decide(observation)\n",
    "        next_observation, reward, done, info = env.step(action) # 执行动作\n",
    "        episode_reward += reward # 收集回合总奖励\n",
    "        if train: # 判断是否需要训练\n",
    "            agent.learn(observation, action, reward, done) # 学习\n",
    "        if done: # 回合结束，跳出循环\n",
    "            break\n",
    "        observation = next_observation\n",
    "    return episode_reward # 返回回合总奖励"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/damonchang/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "2025-02-28 21:30:16.159 python[29341:1566945] _TIPropertyValueIsValid called with 11 on nil context!\n",
      "2025-02-28 21:30:16.159 python[29341:1566945] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 11, bailing.\n",
      "2025-02-28 21:30:16.159 python[29341:1566945] _TIPropertyValueIsValid called with 12 on nil context!\n",
      "2025-02-28 21:30:16.160 python[29341:1566945] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 12, bailing.\n",
      "2025-02-28 21:30:16.160 python[29341:1566945] _TIPropertyValueIsValid called with 11 on nil context!\n",
      "2025-02-28 21:30:16.160 python[29341:1566945] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 11, bailing.\n",
      "2025-02-28 21:30:16.160 python[29341:1566945] _TIPropertyValueIsValid called with 12 on nil context!\n",
      "2025-02-28 21:30:16.160 python[29341:1566945] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 12, bailing.\n",
      "2025-02-28 21:30:16.429 python[29341:1566945] error messaging the mach port for IMKCFRunLoopWakeUpReliable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回合奖励 = -104.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 21:30:20.650 python[29341:1566945] _TIPropertyValueIsValid called with 12 on nil context!\n",
      "2025-02-28 21:30:20.650 python[29341:1566945] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 12, bailing.\n"
     ]
    }
   ],
   "source": [
    "# 让智能体和环境交互一个回合 并现实图形界面\n",
    "env.seed(3) # 设计随机种子 让结果可复现\n",
    "episode_reward = play(env, agent, render=True)\n",
    "print(\"回合奖励 = {}\".format(episode_reward))\n",
    "env.close() #关闭图形界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
